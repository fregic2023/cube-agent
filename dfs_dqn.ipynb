{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "from collections import deque, Counter\n",
    "\n",
    "import visualize_test as cube\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree:\n",
    "    write = 0\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.n_entries = 0\n",
    "\n",
    "    # update to the root node\n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "\n",
    "        self.tree[parent] += change\n",
    "\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    # find sample on leaf node\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "        right = left + 1\n",
    "\n",
    "        if left >= len(self.tree):\n",
    "            return idx\n",
    "\n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s - self.tree[left])\n",
    "\n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    # store priority and sample\n",
    "    def add(self, p, data):\n",
    "        idx = self.write + self.capacity - 1\n",
    "\n",
    "        self.data[self.write] = data\n",
    "        self.update(idx, p)\n",
    "\n",
    "        self.write += 1\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "\n",
    "        if self.n_entries < self.capacity:\n",
    "            self.n_entries += 1\n",
    "\n",
    "    # update priority\n",
    "    def update(self, idx, p):\n",
    "        change = p - self.tree[idx]\n",
    "\n",
    "        self.tree[idx] = p\n",
    "        self._propagate(idx, change)\n",
    "\n",
    "    # get priority and sample\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        data_idx = idx - self.capacity + 1\n",
    "\n",
    "        return (self.tree[idx], self.data[data_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:  # stored as ( s, a, r, s_ ) in SumTree\n",
    "    e = 0.01\n",
    "    a = 0.8\n",
    "    beta = 0.3\n",
    "    beta_increment_per_sampling = 0.0005\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def _get_priority(self, error):\n",
    "        return (np.abs(error) + self.e) ** self.a\n",
    "\n",
    "    def add(self, error, sample):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.add(p, sample)\n",
    "\n",
    "    def sample(self, n):\n",
    "        batch = []\n",
    "        segment = self.tree.total() / n\n",
    "        priorities = []\n",
    "\n",
    "        self.beta = np.min([1., self.beta + self.beta_increment_per_sampling])\n",
    "\n",
    "        for i in range(n):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "\n",
    "            s = np.random.uniform(a, b)\n",
    "            p, data = self.tree.get(s)\n",
    "            priorities.append(p)\n",
    "            batch.append(data)\n",
    "\n",
    "        sampling_probabilities = priorities / self.tree.total()\n",
    "        is_weight = np.power(self.tree.n_entries * sampling_probabilities, -self.beta)\n",
    "        is_weight /= is_weight.max()\n",
    "\n",
    "        return batch, is_weight\n",
    "\n",
    "    def update(self, idx, error):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.update(idx, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_model(tf.keras.models.Model):\n",
    "    def __init__(self, action_space):\n",
    "        super().__init__()\n",
    "        self.rescaling_layer = tf.keras.layers.Rescaling(1./6)\n",
    "\n",
    "        self.conv_layer = tf.keras.layers.Conv3D(32, (2, 2, 2), activation='relu')\n",
    "        self.pooling_layer = tf.keras.layers.MaxPool3D((2, 2, 2))\n",
    "\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.dense_layer0 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        \n",
    "        self.value_layer = tf.keras.layers.Dense(1, activation='linear')\n",
    "        self.advantage_layer = tf.keras.layers.Dense(action_space, activation='linear')\n",
    "\n",
    "    def call(self, x):\n",
    "        r = self.rescaling_layer(x)\n",
    "\n",
    "        c = self.conv_layer(r)\n",
    "        p = self.pooling_layer(c)\n",
    "\n",
    "        f = self.flatten_layer(p)\n",
    "\n",
    "        d = self.dense_layer0(f)\n",
    "\n",
    "        v = self.value_layer(d)\n",
    "        a = self.advantage_layer(d)\n",
    "\n",
    "        avg_a = tf.math.reduce_mean(a, axis=1, keepdims=True)\n",
    "        q = v + a - avg_a\n",
    "\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_agent:\n",
    "    def __init__(self, memory_size=100000, state_shape=[3, 3, 3, 6], action_space=18, batch_size=64):\n",
    "\n",
    "        self.state_shape = state_shape\n",
    "        self.state_shape.insert(0, batch_size)\n",
    "\n",
    "        self.action_size = action_space\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.memory = Memory(memory_size)\n",
    "\n",
    "        self.gamma = 0.995    # discount rate\n",
    "\n",
    "        # EXPLORATION HYPERPARAMETERS for epsilon and epsilon greedy strategy\n",
    "        self.epsilon = 1.0 # exploration probability at start\n",
    "        self.epsilon_min = 0.001 # minimum exploration probability\n",
    "        self.epsilon_decay = 0.000015 # exponential decay rate for exploration prob\n",
    "\n",
    "        self.explore_probability = 0\n",
    "\n",
    "        self.decay_step = 0\n",
    "\n",
    "        self.tau = 1e-2 # target network soft update hyperparameter\n",
    "\n",
    "        self.target_update_counter = 0\n",
    "        self.target_update_interval = 100\n",
    "\n",
    "        # create main model and target model\n",
    "        try:\n",
    "            self.train_model = tf.keras.models.load_model('./model')\n",
    "            self.target_model = tf.keras.models.load_model('./model')\n",
    "\n",
    "        except OSError:\n",
    "            self.train_model = DQN_model(self.action_size)\n",
    "            self.target_model = DQN_model(self.action_size)\n",
    "\n",
    "            self.update_model()\n",
    "\n",
    "        self.optim = tf.keras.optimizers.legacy.RMSprop(learning_rate=1e-4)\n",
    "\n",
    "    def update_model(self) -> None:\n",
    "        self.target_model.set_weights(self.train_model.get_weights())\n",
    "\n",
    "    def soft_update_model(self) -> None:\n",
    "        train_weight = np.array(self.train_model.get_weights(), dtype=object)\n",
    "        target_weight = np.array(self.target_model.get_weights(), dtype=object)\n",
    "\n",
    "        weight = train_weight * self.tau + target_weight * (1 - self.tau)\n",
    "        self.target_model.set_weights(weight)\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done) -> None:\n",
    "        experience = state, action, reward, next_state, done\n",
    "        td_error = reward + self.gamma * np.argmax(self.target_model(next_state)[0]) - np.argmax(self.train_model(state)[0])\n",
    "\n",
    "        self.memory.add(td_error, experience)\n",
    "\n",
    "    def convert_memory_to_input(self, batch):\n",
    "        s, a, r, ns, d = zip(*batch)\n",
    "\n",
    "        states = tf.convert_to_tensor(s).reshape(self.state_shape)\n",
    "        action = tf.convert_to_tensor(a)\n",
    "        rewards = tf.convert_to_tensor(r)\n",
    "        next_states = tf.convert_to_tensor(ns).reshape(self.state_shape)\n",
    "        dones = tf.convert_to_tensor(d)\n",
    "\n",
    "        return states, action, rewards, next_states, dones\n",
    "\n",
    "    def return_action_list(self, state):\n",
    "        self.explore_probability = self.epsilon_min + (self.epsilon - self.epsilon_min) * np.exp(-self.epsilon_decay * self.decay_step)\n",
    "\n",
    "        action_list = list(self.train_model(state)[0])\n",
    "        return_array = []\n",
    "\n",
    "        while len(return_array) < self.action_size:\n",
    "            if self.explore_probability > np.random.random():\n",
    "                action = np.random.randint(0, self.action_size)\n",
    "                if any(action == i for i in return_array):\n",
    "                    continue\n",
    "                \n",
    "            else:\n",
    "                action = np.argmax(action_list)\n",
    "                action_list[action] = 0\n",
    "\n",
    "            return_array.append(action)\n",
    "            \n",
    "        return return_array\n",
    "\n",
    "    def run(self):\n",
    "        if self.memory.tree.total() < self.batch_size:\n",
    "            return np.array([0])\n",
    "        \n",
    "        batch, _ = self.memory.sample(self.batch_size)\n",
    "\n",
    "        try:\n",
    "            states, actions, rewards, next_states, dones = self.convert_memory_to_input(batch)\n",
    "        except TypeError:\n",
    "            return np.array(0)\n",
    "\n",
    "        loss = self.learn(states, actions, rewards, next_states, dones)\n",
    "\n",
    "        return loss.numpy().mean()\n",
    "\n",
    "    @tf.function\n",
    "    def learn(self, states, actions, rewards, next_states, dones):\n",
    "        target_q = rewards + (1 - dones) * self.gamma * tf.reduce_max(self.target_model(next_states), axis=1, keepdims=True)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.train_model.trainable_variables)\n",
    "\n",
    "            q = self.train_model(states)\n",
    "\n",
    "            onehot_actions = tf.one_hot(actions, self.action_size)\n",
    "            val = tf.reduce_sum(onehot_actions * q, axis=1)\n",
    "\n",
    "            loss = tf.keras.losses.mean_squared_error(target_q, val)\n",
    "\n",
    "        grads = tape.gradient(loss, self.train_model.trainable_weights)\n",
    "        self.optim.apply_gradients(zip(grads, self.train_model.trainable_weights))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, cube_name):\n",
    "        self.cube_name = cube_name\n",
    "        self.cube = cube.Cube(cube_name)\n",
    "        self.action_list = [\"R\",\"R2\",\"R'\",\"U\",\"U2\",\"U'\",\"F\",\"F2\",\"F'\",\"L\",\"L2\",\"L'\",\"D\",\"D2\",\"D'\",\"B\",\"B2\",\"B'\",]\n",
    "\n",
    "        self.shuffle_num = 1\n",
    "        self.max_depth = 20\n",
    "        self.action_counter = 0\n",
    "        self.reward_history = []\n",
    "\n",
    "    def reset_env(self):\n",
    "        self.cube = cube.Cube(self.cube_name)\n",
    "\n",
    "        return self.shuffle_num\n",
    "\n",
    "    def to_scramble(self, action):\n",
    "        action = self.action_list[action]\n",
    "\n",
    "        return action\n",
    "\n",
    "    def shuffle(self, shuffle_num):\n",
    "        scramble = self.cube.generate_scramble(shuffle_num)\n",
    "        self.cube.execute(scramble)\n",
    "        state = self.cube.get_state()\n",
    "\n",
    "        return np.array([state], dtype=np.float32), scramble\n",
    "\n",
    "    def step(self, act, action_num):\n",
    "        turning_str = self.to_scramble(act)\n",
    "        self.cube.execute(turning_str)\n",
    "\n",
    "        next_state = self.cube.get_state()\n",
    "\n",
    "        done = self.cube.solved()\n",
    "\n",
    "        reward = int(done) * 10 * np.exp(self.shuffle_num - action_num)\n",
    "\n",
    "        return np.array(reward, dtype=np.float32), np.array([next_state], dtype=np.float32), done, turning_str\n",
    "\n",
    "    def depth_step(self, depth, state, action_list, human_actions):\n",
    "        self.action_counter += 1\n",
    "        \n",
    "        if depth == self.max_depth:\n",
    "            return False, human_actions[0:-1]\n",
    "\n",
    "        for action in action_list[0:19-depth]:\n",
    "            reward, next_state, done, human_action = self.step(action, depth)\n",
    "            agent.memorize(state, action, reward, next_state, done)\n",
    "\n",
    "            human_actions.append(human_action)\n",
    "            self.reward_history.append(reward)\n",
    "\n",
    "            if done:\n",
    "                print(f\"==={human_actions}===\")\n",
    "            #     return True, human_actions\n",
    "\n",
    "            next_action_list = agent.return_action_list(next_state)\n",
    "            is_end, human_actions = self.depth_step(depth+1, next_state, next_action_list, human_actions)\n",
    "\n",
    "            self.cube.reverse_execute(human_action)\n",
    "\n",
    "            # if is_end:\n",
    "            #     return True, human_actions\n",
    "\n",
    "        return False, human_actions[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 19:53:33.926731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-28 19:53:33.928958: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "completed_capacity = 1000\n",
    "\n",
    "agent = DQN_agent()\n",
    "env = Environment(\"3x3x3\")\n",
    "\n",
    "retried = 0\n",
    "success_que = deque(maxlen=100)\n",
    "loss = 0\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "e = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===['D', 'D2']===\n",
      "===['D2', 'D']===\n",
      "===[\"D'\"]===\n",
      "1 | 0 | 1.0\n",
      "D  / 343\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['F']===\n",
      "===[\"F'\", 'F2']===\n",
      "===['F2', \"F'\"]===\n",
      "1 | 0 | 0.999985015112387\n",
      "F'  / 686\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['F2']===\n",
      "===[\"F'\", \"F'\"]===\n",
      "===['F', 'F']===\n",
      "1 | 0 | 0.9999700304495455\n",
      "F2  / 1029\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"B'\", \"B'\"]===\n",
      "===['B', 'B']===\n",
      "===['B2']===\n",
      "1 | 0 | 0.9999550460114723\n",
      "B2  / 1372\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['B2', 'B']===\n",
      "===['B', 'B2']===\n",
      "===[\"B'\"]===\n",
      "1 | 0 | 0.9999400617981641\n",
      "B  / 1715\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"U'\"]===\n",
      "===['U2', 'U']===\n",
      "===['U', 'U2']===\n",
      "1 | 0 | 0.9999250778096173\n",
      "U  / 2058\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['U']===\n",
      "===[\"U'\", 'U2']===\n",
      "===['U2', \"U'\"]===\n",
      "1 | 0 | 0.9999100940458286\n",
      "U'  / 2401\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"D'\", \"D'\"]===\n",
      "===['D', 'D']===\n",
      "===['D2']===\n",
      "1 | 0 | 0.9998951105067947\n",
      "D2  / 2744\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"B'\", 'B2']===\n",
      "===['B2', \"B'\"]===\n",
      "===['B']===\n",
      "1 | 0 | 0.9998801271925123\n",
      "B'  / 3087\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"D'\", 'D2']===\n",
      "===['D']===\n",
      "===['D2', \"D'\"]===\n",
      "1 | 0 | 0.9998651441029779\n",
      "D'  / 3430\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"D'\", 'D2']===\n",
      "===['D']===\n",
      "===['D2', \"D'\"]===\n",
      "1 | 0 | 0.999850161238188\n",
      "D'  / 3773\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['D']===\n",
      "===['D2', \"D'\"]===\n",
      "===[\"D'\", 'D2']===\n",
      "1 | 0 | 0.9998351785981395\n",
      "D'  / 4116\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['D', 'D']===\n",
      "===[\"D'\", \"D'\"]===\n",
      "===['D2']===\n",
      "1 | 0 | 0.999820196182829\n",
      "D2  / 4459\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['U2', \"U'\"]===\n",
      "===[\"U'\", 'U2']===\n",
      "===['U']===\n",
      "1 | 0 | 0.999805213992253\n",
      "U'  / 4802\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['L2', 'L']===\n",
      "===[\"L'\"]===\n",
      "===['L', 'L2']===\n",
      "1 | 0 | 0.9997902320264082\n",
      "L  / 5145\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['R', 'R']===\n",
      "===[\"R'\", \"R'\"]===\n",
      "===['R2']===\n",
      "1 | 0 | 0.9997752502852911\n",
      "R2  / 5488\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['U2', 'U']===\n",
      "===[\"U'\"]===\n",
      "===['U', 'U2']===\n",
      "1 | 0 | 0.9997602687688985\n",
      "U  / 5831\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"D'\", \"D'\"]===\n",
      "===['D', 'D']===\n",
      "===['D2']===\n",
      "1 | 0 | 0.9997452874772268\n",
      "D2  / 6174\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['R', 'R2']===\n",
      "===['R2', 'R']===\n",
      "===[\"R'\"]===\n",
      "1 | 0 | 0.999730306410273\n",
      "R  / 6517\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['U2', 'U']===\n",
      "===['U', 'U2']===\n",
      "===[\"U'\"]===\n",
      "1 | 0 | 0.9997153255680334\n",
      "U  / 6860\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['F', 'F']===\n",
      "===['F2']===\n",
      "===[\"F'\", \"F'\"]===\n",
      "1 | 0 | 0.9997003449505049\n",
      "F2  / 7203\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['D2']===\n",
      "===['D', 'D']===\n",
      "===[\"D'\", \"D'\"]===\n",
      "1 | 0 | 0.9996853645576838\n",
      "D2  / 7546\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"B'\"]===\n",
      "===['B', 'B2']===\n",
      "===['B2', 'B']===\n",
      "1 | 0 | 0.999670384389567\n",
      "B  / 7889\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"R'\"]===\n",
      "===['R2', 'R']===\n",
      "===['R', 'R2']===\n",
      "1 | 0 | 0.9996554044461511\n",
      "R  / 8232\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"R'\", \"R'\"]===\n",
      "===['R2']===\n",
      "===['R', 'R']===\n",
      "1 | 0 | 0.9996404247274324\n",
      "R2  / 8575\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['L', 'L2']===\n",
      "===['L2', 'L']===\n",
      "===[\"L'\"]===\n",
      "1 | 0 | 0.999625445233408\n",
      "L  / 8918\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['L', 'L2']===\n",
      "===['L2', 'L']===\n",
      "===[\"L'\"]===\n",
      "1 | 0 | 0.9996104659640743\n",
      "L  / 9261\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['D2']===\n",
      "===['D', 'D']===\n",
      "===[\"D'\", \"D'\"]===\n",
      "1 | 0 | 0.999595486919428\n",
      "D2  / 9604\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['D2']===\n",
      "===['D', 'D']===\n",
      "===[\"D'\", \"D'\"]===\n",
      "1 | 0 | 0.9995805080994656\n",
      "D2  / 9947\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['F']===\n",
      "===['F2', \"F'\"]===\n",
      "===[\"F'\", 'F2']===\n",
      "1 | 0 | 0.999565529504184\n",
      "F'  / 10290\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"D'\", \"D'\"]===\n",
      "===['D', 'D']===\n",
      "===['D2']===\n",
      "1 | 0 | 0.9995505511335794\n",
      "D2  / 10633\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"L'\", 'L2']===\n",
      "===['L2', \"L'\"]===\n",
      "===['L']===\n",
      "1 | 0 | 0.9995355729876488\n",
      "L'  / 10976\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['U2', 'U']===\n",
      "===['U', 'U2']===\n",
      "===[\"U'\"]===\n",
      "1 | 0 | 0.9995205950663887\n",
      "U  / 11319\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['D2', \"D'\"]===\n",
      "===[\"D'\", 'D2']===\n",
      "===['D']===\n",
      "1 | 0 | 0.9995056173697957\n",
      "D'  / 11662\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['F2', 'F']===\n",
      "===['F', 'F2']===\n",
      "===[\"F'\"]===\n",
      "1 | 0 | 0.9994906398978665\n",
      "F  / 12005\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"U'\"]===\n",
      "===['U', 'U2']===\n",
      "===['U2', 'U']===\n",
      "1 | 0 | 0.9994756626505975\n",
      "U  / 12348\n",
      "[]-False\n",
      "----------------------------------\n",
      "===[\"F'\"]===\n",
      "===['F2', 'F']===\n",
      "===['F', 'F2']===\n",
      "1 | 0 | 0.9994606856279857\n",
      "F  / 12691\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['B2', 'B']===\n",
      "===[\"B'\"]===\n",
      "===['B', 'B2']===\n",
      "1 | 0 | 0.9994457088300277\n",
      "B  / 13034\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['U']===\n",
      "===['U2', \"U'\"]===\n",
      "===[\"U'\", 'U2']===\n",
      "1 | 0 | 0.9994307322567197\n",
      "U'  / 13377\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['B2', \"B'\"]===\n",
      "===['B']===\n",
      "===[\"B'\", 'B2']===\n",
      "1 | 0 | 0.9994157559080588\n",
      "B'  / 13720\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['R2', \"R'\"]===\n",
      "===[\"R'\", 'R2']===\n",
      "===['R']===\n",
      "1 | 0 | 0.9994007797840414\n",
      "R'  / 14063\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['D', 'D2']===\n",
      "===[\"D'\"]===\n",
      "===['D2', 'D']===\n",
      "1 | 0 | 0.9993858038846641\n",
      "D  / 14406\n",
      "[]-False\n",
      "----------------------------------\n",
      "===['F2', \"F'\"]===\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    shuffle_num = env.reset_env()\n",
    "    state, scramble = env.shuffle(shuffle_num)\n",
    "    env.max_depth = min(20, shuffle_num*2)\n",
    "\n",
    "    action_list = agent.return_action_list(state)\n",
    "    is_end, human_actions = env.depth_step(0, state, action_list, [])\n",
    "    success_que.append(is_end)\n",
    "\n",
    "    success = success_que.count(True)\n",
    "    \n",
    "    print(f\"{shuffle_num} | {success} | {agent.explore_probability}\")\n",
    "    print(f\"{scramble} / {env.action_counter}\")\n",
    "    print(f\"{human_actions}-{is_end}\")\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        loss = agent.run().mean()\n",
    "        loss_history.append(loss)\n",
    "\n",
    "    if e % 500 == 0:\n",
    "        agent.soft_update_model()\n",
    "\n",
    "    # if success == 100:\n",
    "    #     env.shuffle_num += 1\n",
    "\n",
    "    e += 1\n",
    "    agent.decay_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(env.reward_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "# plt.savefig('m.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(try_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('m.txt', np.array([max_count, e, shuffle_num, agent.explore_probability]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train_model.save('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
