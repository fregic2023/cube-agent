{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as rand\n",
    "\n",
    "from collections import deque, Counter\n",
    "\n",
    "import cube_env as cube\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree:\n",
    "    write = 0\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.n_entries = 0\n",
    "\n",
    "    # update to the root node\n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "\n",
    "        self.tree[parent] += change\n",
    "\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    # find sample on leaf node\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "        right = left + 1\n",
    "\n",
    "        if left >= len(self.tree):\n",
    "            return idx\n",
    "\n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s - self.tree[left])\n",
    "\n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    # store priority and sample\n",
    "    def add(self, p, data):\n",
    "        idx = self.write + self.capacity - 1\n",
    "\n",
    "        self.data[self.write] = data\n",
    "        self.update(idx, p)\n",
    "\n",
    "        self.write += 1\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "\n",
    "        if self.n_entries < self.capacity:\n",
    "            self.n_entries += 1\n",
    "\n",
    "    # update priority\n",
    "    def update(self, idx, p):\n",
    "        change = p - self.tree[idx]\n",
    "\n",
    "        self.tree[idx] = p\n",
    "        self._propagate(idx, change)\n",
    "\n",
    "    # get priority and sample\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        data_idx = idx - self.capacity + 1\n",
    "\n",
    "        return (self.tree[idx], self.data[data_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:  # stored as ( s, a, r, s_ ) in SumTree\n",
    "    e = 0.01\n",
    "    a = 0.8\n",
    "    beta = 0.3\n",
    "    beta_increment_per_sampling = 0.0005\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def _get_priority(self, error):\n",
    "        return (np.abs(error) + self.e) ** self.a\n",
    "\n",
    "    def add(self, error, sample):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.add(p, sample)\n",
    "\n",
    "    def sample(self, n):\n",
    "        batch = []\n",
    "        segment = self.tree.total() / n\n",
    "        priorities = []\n",
    "\n",
    "        self.beta = np.min([1., self.beta + self.beta_increment_per_sampling])\n",
    "\n",
    "        for i in range(n):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "\n",
    "            s = np.random.uniform(a, b)\n",
    "            p, data = self.tree.get(s)\n",
    "            priorities.append(p)\n",
    "            batch.append(data)\n",
    "\n",
    "        sampling_probabilities = priorities / self.tree.total()\n",
    "        is_weight = np.power(self.tree.n_entries * sampling_probabilities, -self.beta)\n",
    "        is_weight /= is_weight.max()\n",
    "\n",
    "        return batch, is_weight\n",
    "\n",
    "    def update(self, idx, error):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.update(idx, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_model(tf.keras.models.Model):\n",
    "    def __init__(self, action_space):\n",
    "        super().__init__()\n",
    "        self.rescaling_layer = tf.keras.layers.Rescaling(1./6)\n",
    "\n",
    "        self.conv_layer = tf.keras.layers.Conv3D(32, (2, 2, 2), activation='relu')\n",
    "        self.pooling_layer = tf.keras.layers.MaxPool3D((2, 2, 2))\n",
    "\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.conv_dense_layer = tf.keras.layers.Dense(32, activation='relu')\n",
    "\n",
    "        self.lstm_block = tf.keras.Sequential()\n",
    "        self.lstm_block.add(tf.keras.layers.LSTM(32, input_shape=(20, 1), activation='tanh'))\n",
    "        self.lstm_block.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "        \n",
    "        self.concat_layer = tf.keras.layers.Concatenate()\n",
    "        self.concat_dense_layer = tf.keras.layers.Dense(32, activation='relu')\n",
    "\n",
    "        self.value_layer = tf.keras.layers.Dense(1, activation='linear')\n",
    "        self.advantage_layer = tf.keras.layers.Dense(action_space, activation='linear')\n",
    "\n",
    "    def call(self, x):\n",
    "        cube_state = x[0]\n",
    "        action_state = x[1]\n",
    "\n",
    "        r = self.rescaling_layer(cube_state)\n",
    "        c = self.conv_layer(r)\n",
    "        p = self.pooling_layer(c)\n",
    "        f = self.flatten_layer(p)\n",
    "\n",
    "        cd = self.conv_dense_layer(f)\n",
    "\n",
    "        ld = self.lstm_block(action_state)\n",
    "\n",
    "        concat = self.concat_layer([cd, ld])\n",
    "        o = self.concat_dense_layer(concat)\n",
    "\n",
    "        v = self.value_layer(o)\n",
    "        a = self.advantage_layer(o)\n",
    "\n",
    "        avg_a = tf.math.reduce_mean(a, axis=1, keepdims=True)\n",
    "        q = v + a - avg_a\n",
    "\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_agent:\n",
    "    def __init__(self, memory_size=100000, state_shape=([3, 3, 3, 6], [20]), action_space=18, batch_size=64):\n",
    "        self.state_shape = state_shape\n",
    "        self.state_shape[0].insert(0, batch_size)\n",
    "        self.state_shape[1].insert(0, batch_size)\n",
    "\n",
    "        self.action_size = action_space\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.memory = Memory(memory_size)\n",
    "\n",
    "        self.gamma = 0.995    # discount rate\n",
    "\n",
    "        # EXPLORATION HYPERPARAMETERS for epsilon and epsilon greedy strategy\n",
    "        self.epsilon = 1.5 # exploration probability at start\n",
    "        self.epsilon_min = 0.001 # minimum exploration probability\n",
    "        self.epsilon_decay = 0.000025 # exponential decay rate for exploration prob\n",
    "\n",
    "        self.explore_probability = 0 \n",
    "\n",
    "        self.tau = 1e-2 # target network soft update hyperparameter\n",
    "\n",
    "        self.target_update_counter = 0\n",
    "        self.target_update_interval = 100\n",
    "\n",
    "        # create main model and target model\n",
    "        try:\n",
    "            self.train_model = tf.keras.models.load_model('./model')\n",
    "            self.target_model = tf.keras.models.load_model('./model')\n",
    "\n",
    "        except OSError:\n",
    "            self.train_model = DQN_model(self.action_size)\n",
    "            self.target_model = DQN_model(self.action_size)\n",
    "\n",
    "            self.update_model()\n",
    "\n",
    "        self.optim = tf.keras.optimizers.legacy.RMSprop(learning_rate=1e-4)\n",
    "\n",
    "    def update_model(self) -> None:\n",
    "        self.target_model.set_weights(self.train_model.get_weights())\n",
    "\n",
    "    def soft_update_model(self) -> None:\n",
    "        train_weight = np.array(self.train_model.get_weights(), dtype=object)\n",
    "        target_weight = np.array(self.target_model.get_weights(), dtype=object)\n",
    "\n",
    "        weight = train_weight * self.tau + target_weight * (1 - self.tau)\n",
    "        self.target_model.set_weights(weight)\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done) -> None:\n",
    "        experience = state, action, reward, next_state, done\n",
    "        td_error = reward + self.gamma * np.argmax(self.target_model(next_state)[0]) - np.argmax(self.train_model(state)[0])\n",
    "\n",
    "        self.memory.add(td_error, experience)\n",
    "\n",
    "    def process_state(self, states):\n",
    "        state_list = []\n",
    "        for s in states:\n",
    "            print(s[0].shape)\n",
    "            print(s[1].shape)\n",
    "            state = [tf.convert_to_tensor(s[0]).reshape(self.state_shape[0]), tf.convert_to_tensor(s[1]).reshape(self.state_shape[1])]\n",
    "            state_list.append(state)\n",
    "\n",
    "        return state_list\n",
    "\n",
    "    def convert_memory_to_input(self, batch):\n",
    "        s, a, r, ns, d = zip(*batch)\n",
    "\n",
    "        states = s\n",
    "        action = tf.convert_to_tensor(a)\n",
    "        rewards = tf.convert_to_tensor(r)\n",
    "        next_states = ns\n",
    "        dones = tf.convert_to_tensor(d)\n",
    "\n",
    "        return states, action, rewards, next_states, dones\n",
    "\n",
    "    def act(self, state, decay_step):\n",
    "        self.explore_probability = self.epsilon_min + (self.epsilon - self.epsilon_min) * np.exp(-self.epsilon_decay * decay_step)\n",
    "\n",
    "        if self.explore_probability > np.random.random():\n",
    "            action = np.random.randint(0, self.action_size)\n",
    "\n",
    "        else:\n",
    "            action = np.argmax(self.train_model(state), axis=1)[0]\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def run(self):\n",
    "        if self.memory.tree.total() < self.batch_size:\n",
    "            return np.array([0])\n",
    "        \n",
    "        batch, _ = self.memory.sample(self.batch_size)\n",
    "\n",
    "        try:\n",
    "            states, actions, rewards, next_states, dones = self.convert_memory_to_input(batch)\n",
    "        except TypeError:\n",
    "            return np.array(0)\n",
    "\n",
    "        loss = self.learn(states, actions, rewards, next_states, dones)\n",
    "\n",
    "        return loss.numpy().mean()\n",
    "\n",
    "    @tf.function\n",
    "    def learn(self, states, actions, rewards, next_states, dones):\n",
    "        target_q = rewards + (1 - dones) * self.gamma * tf.reduce_max(self.target_model(next_states), axis=1, keepdims=True)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.train_model.trainable_variables)\n",
    "\n",
    "            q = self.train_model(states)\n",
    "\n",
    "            onehot_actions = tf.one_hot(actions, self.action_size)\n",
    "            val = tf.reduce_sum(onehot_actions * q, axis=1)\n",
    "\n",
    "            loss = tf.keras.losses.mean_squared_error(target_q, val)\n",
    "\n",
    "        grads = tape.gradient(loss, self.train_model.trainable_weights)\n",
    "        self.optim.apply_gradients(zip(grads, self.train_model.trainable_weights))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, cube_name, max_capacity) -> None:\n",
    "        self.cube_name = cube_name\n",
    "        self.max_capacity = max_capacity\n",
    "        self.cube = cube.Cube(cube_name)\n",
    "        self.action_list = [\"R\",\"R2\",\"R'\",\"U\",\"U2\",\"U'\",\"F\",\"F2\",\"F'\",\"L\",\"L2\",\"L'\",\"D\",\"D2\",\"D'\",\"B\",\"B2\",\"B'\",]\n",
    "        self.shuffle_que = deque([1 for i in range(max_capacity)], maxlen=max_capacity)\n",
    "\n",
    "        self.act_count = 0\n",
    "        self.max_action = 20\n",
    "        self.action_state = np.array([50 for i in range(self.max_action)]).reshape(1, self.max_action, 1)\n",
    "\n",
    "    def reset_shuffle_que(self, num):\n",
    "        self.shuffle_que = deque([num for i in range(self.max_capacity)], maxlen=self.max_capacity)\n",
    "\n",
    "    def shuffle_num_info(self):\n",
    "        return np.bincount(self.shuffle_que)\n",
    "\n",
    "    def reset_env(self):\n",
    "        self.cube = cube.Cube(self.cube_name)\n",
    "        self.action_state = np.array([50 for i in range(self.max_action)]).reshape(1, self.max_action, 1)\n",
    "        self.act_count = 0\n",
    "\n",
    "        return self.shuffle_que.popleft()\n",
    "\n",
    "    def to_scramble(self, action):\n",
    "        action = self.action_list[action]\n",
    "\n",
    "        return action\n",
    "\n",
    "    def shuffle(self, shuffle_num):\n",
    "        scramble = self.cube.generate_scramble(shuffle_num)\n",
    "        self.cube.execute(scramble)\n",
    "        state = self.cube.get_state()\n",
    "\n",
    "        return (np.array([state]), self.action_state), scramble\n",
    "    \n",
    "    def step(self, act):\n",
    "        turning_str = self.to_scramble(act)\n",
    "        self.cube.execute(turning_str)\n",
    "\n",
    "        next_state = self.cube.get_state()\n",
    "        self.action_state[0][self.act_count][0] = act\n",
    "\n",
    "        done = self.cube.solved()\n",
    "\n",
    "        reward = int(done) * 10\n",
    "\n",
    "        self.act_count += 1\n",
    "\n",
    "        return np.array(reward, dtype=np.float32), (np.array([next_state]), self.action_state), done, turning_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 22:50:34.202073: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 22:50:34.203134: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "completed_capacity = 1000\n",
    "\n",
    "agent = DQN_agent()\n",
    "env = Environment(\"3x3x3\", int(1e+4))\n",
    "# end_threshold =  ## will be\n",
    "\n",
    "retried = 0\n",
    "completed = deque(maxlen=completed_capacity)\n",
    "loss = 0\n",
    "\n",
    "try_history = []\n",
    "loss_history = []\n",
    "\n",
    "e = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0|999 >> step:3, result:0.0, prob:1.5\n",
      "    U'  | [\"R'\", \"U'\", 'L'] -> loss:[0]\n",
      "    1 : 10000 >> [10000]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_19627/3555913365.py\", line 104, in learn  *\n        target_q = rewards + (1 - dones) * self.gamma * tf.reduce_max(self.target_model(next_states), axis=1, keepdims=True)\n    File \"/home/kang/anaconda3/envs/lab/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file351eqma3.py\", line 12, in tf__call\n        r = ag__.converted_call(ag__.ld(self).rescaling_layer, (ag__.ld(cube_state),), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"dqn_model_1\" (type DQN_model).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_19627/438799113.py\", line 27, in call  *\n            r = self.rescaling_layer(cube_state)\n        File \"/home/kang/anaconda3/envs/lab/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        TypeError: Exception encountered when calling layer \"rescaling_1\" (type Rescaling).\n        \n        Cannot convert a list containing a tensor of dtype <dtype: 'int64'> to <dtype: 'float32'> (Tensor is: <tf.Tensor 'next_states_1:0' shape=(1, 20, 1) dtype=int64>)\n        \n        Call arguments received by layer \"rescaling_1\" (type Rescaling):\n          • inputs=('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)')\n    \n    \n    Call arguments received by layer \"dqn_model_1\" (type DQN_model):\n      • x=[('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)')]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m shuffle_num_array \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mshuffle_num_info()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m e \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     loss \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     loss_history\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m e \u001b[39m%\u001b[39m \u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearn(\u001b[39mlist\u001b[39;49m(states), actions, rewards, \u001b[39mlist\u001b[39;49m(next_states), dones)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kang/code/ai/cube-agent/dqn_cnn_lstm.ipynb#X11sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/anaconda3/envs/lab/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file8mc2q0us.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__learn\u001b[0;34m(self, states, actions, rewards, next_states, dones)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m target_q \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(rewards) \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ag__\u001b[39m.\u001b[39mld(dones)) \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreduce_max, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtarget_model, (ag__\u001b[39m.\u001b[39mld(next_states),), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m     12\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mwatch, (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrain_model\u001b[39m.\u001b[39mtrainable_variables,), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/anaconda3/envs/lab/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file351eqma3.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m cube_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(x)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m action_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(x)[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m r \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mrescaling_layer, (ag__\u001b[39m.\u001b[39mld(cube_state),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m c \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconv_layer, (ag__\u001b[39m.\u001b[39mld(r),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m p \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mpooling_layer, (ag__\u001b[39m.\u001b[39mld(c),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_19627/3555913365.py\", line 104, in learn  *\n        target_q = rewards + (1 - dones) * self.gamma * tf.reduce_max(self.target_model(next_states), axis=1, keepdims=True)\n    File \"/home/kang/anaconda3/envs/lab/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_file351eqma3.py\", line 12, in tf__call\n        r = ag__.converted_call(ag__.ld(self).rescaling_layer, (ag__.ld(cube_state),), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"dqn_model_1\" (type DQN_model).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_19627/438799113.py\", line 27, in call  *\n            r = self.rescaling_layer(cube_state)\n        File \"/home/kang/anaconda3/envs/lab/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        TypeError: Exception encountered when calling layer \"rescaling_1\" (type Rescaling).\n        \n        Cannot convert a list containing a tensor of dtype <dtype: 'int64'> to <dtype: 'float32'> (Tensor is: <tf.Tensor 'next_states_1:0' shape=(1, 20, 1) dtype=int64>)\n        \n        Call arguments received by layer \"rescaling_1\" (type Rescaling):\n          • inputs=('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)')\n    \n    \n    Call arguments received by layer \"dqn_model_1\" (type DQN_model):\n      • x=[('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)'), ('tf.Tensor(shape=(1, 3, 3, 3, 6), dtype=float32)', 'tf.Tensor(shape=(1, 20, 1), dtype=int64)')]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    shuffle_num = env.reset_env()\n",
    "    state, scramble = env.shuffle(shuffle_num)\n",
    "\n",
    "    human_actions = []\n",
    "    for t in range(1, shuffle_num * 3 + 1):\n",
    "        action = agent.act(state, e)\n",
    "        reward, next_state, done, human_action = env.step(action)\n",
    "\n",
    "        human_actions.append(human_action)\n",
    "\n",
    "        agent.memorize(state, action, reward, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if done:\n",
    "        env.shuffle_que.append(shuffle_num+1)\n",
    "        completed.append(shuffle_num)\n",
    "    else:\n",
    "        env.shuffle_que.append(shuffle_num)\n",
    "        completed.append(0)\n",
    "\n",
    "    try_history.append(t)\n",
    "    count_success = completed_capacity - completed.count(0)\n",
    "    shuffle_num_array = env.shuffle_num_info()\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        loss = agent.run()\n",
    "        loss_history.append(loss)\n",
    "\n",
    "    if e % 500 == 0:\n",
    "        print(f\"{retried}:{e}|{count_success} >> step:{t}, result:{reward}, prob:{agent.explore_probability}\")\n",
    "        print(f\"    {scramble} | {human_actions} -> loss:{loss}\")\n",
    "        print(f\"    {shuffle_num_array.argmax()} : {shuffle_num_array.max()} >> {shuffle_num_array[1::]}\")\n",
    "\n",
    "        agent.soft_update_model()\n",
    "\n",
    "    if e > 5e+4 and count_success < 800:\n",
    "        e = 0\n",
    "        retried += 1\n",
    "\n",
    "        if count_success < 400:\n",
    "            env.reset_shuffle_que(shuffle_num_array.argmax()-1)\n",
    "\n",
    "        else:\n",
    "            env.reset_shuffle_que(shuffle_num_array.argmax())\n",
    "\n",
    "        print(\"==================================================\")\n",
    "        print(\"==================================================\")\n",
    "        agent.update_model()        \n",
    "\n",
    "    if e == 9e+8:\n",
    "        break\n",
    "\n",
    "    e += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.keras.Sequential([tf.keras.layers.LSTM(32, input_shape=(20, 1), activation='tanh')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 1.3870760e-03, -2.2940671e-03,  7.2081101e-09, -5.3315710e-02,\n",
       "         5.7544768e-01, -9.9778146e-01,  1.5083921e-09, -7.8742796e-01,\n",
       "        -9.9161968e-09,  1.2013909e-04, -1.0558030e-02, -7.0250614e-08,\n",
       "        -4.4274030e-04,  8.3024643e-02,  5.0824968e-07,  1.2770890e-04,\n",
       "         9.9967796e-01,  1.2590942e-06, -2.4499542e-07,  3.8128061e-04,\n",
       "         1.6603757e-03, -1.1195554e-04,  8.0032302e-03, -7.5783652e-01,\n",
       "        -9.9949980e-01, -4.3085271e-05,  2.4086852e-04, -7.5951976e-01,\n",
       "         8.5967529e-01,  1.7815448e-01,  9.9997133e-01,  1.4723612e-02]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "# plt.savefig('m.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(try_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e > 5e+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train_model.save('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
